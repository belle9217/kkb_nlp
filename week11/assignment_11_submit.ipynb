{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Review the course programming code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_price = [1, 5, 8, 9, 10, 17, 17, 20, 24, 30, 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "price = defaultdict(int)\n",
    "for i, p in enumerate(original_price):\n",
    "    price[i+1] = p\n",
    "\n",
    "solution = {}\n",
    "\n",
    "#方法1：利用字典max_price记录所有<=n的最优切割方法\n",
    "def cut(n):\n",
    "    max_price = {}\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        max_price[i], split = max([(price[i], 0)] + [(max_price[j] + max_price[i-j], j) for j in range(1, i)],\n",
    "                                       key = lambda x:x[0])\n",
    "        solution[i] = (i - split, split)\n",
    "        \n",
    "    return max_price[n], parse(n)\n",
    "\n",
    "def parse(n):\n",
    "    left, right = solution[n]\n",
    "    if right == 0:\n",
    "        return [left]\n",
    "    else:\n",
    "        return parse(left) + parse(right)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, [11, 6, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def memo(f):\n",
    "    memo.already_computed = {}\n",
    "    @wraps(f)\n",
    "    def _wrap(arg):\n",
    "        if arg in memo.already_computed:\n",
    "            result = memo.already_computed[arg]\n",
    "        else:\n",
    "            result = f(arg)\n",
    "            memo.already_computed[arg] = result\n",
    "        return result\n",
    "    return _wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#方法2：利用装饰器@memo的方法记录缓存\n",
    "@memo\n",
    "def cut(n):\n",
    "    max_price, split = max([(price[n], 0)] + [(cut(j) + cut(n-j), j) for j in range(1, n)],\n",
    "                                       key = lambda x:x[0])\n",
    "    solution[n] = (n - split, split)    \n",
    "    return max_price\n",
    "\n",
    "def parse(n):\n",
    "    left, right = solution[n]\n",
    "    if right == 0:\n",
    "        return [left]\n",
    "    else:\n",
    "        return parse(left) + parse(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 6, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Complete the Edit-Distance Problem Solution, by which we could get the detailed transformer procedure of two string X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "operations = {}\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=2**10)\n",
    "def edit_distance(s1, s2):\n",
    "    \n",
    "    if len(s1) == 0:\n",
    "        return len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    \n",
    "    if s1[-1] == s2[-1]:\n",
    "        dist, op = min((edit_distance(s1[:-1], s2[:-1]),'Do Nothing'),\n",
    "                       (edit_distance(s1[:-1], s2) + 1, 'DEL {}'.format(s1[-1])),\n",
    "                       (edit_distance(s1, s2[:-1]) + 1, 'ADD {}'.format(s2[-1])), \n",
    "                        key = lambda x:x[0])\n",
    "        operations[(s1, s2)] = op\n",
    "        return dist\n",
    "    else:\n",
    "        dist, op = min((edit_distance(s1[:-1], s2[:-1]) + 1, 'SUB {}->{}'.format(s1[-1], s2[-1])),\n",
    "                       (edit_distance(s1[:-1], s2) + 1, 'DEL {}'.format(s1[-1])),\n",
    "                       (edit_distance(s1, s2[:-1]) + 1, 'ADD {}'.format(s2[-1])),\n",
    "                        key = lambda x:x[0])\n",
    "        operations[(s1, s2)] = op\n",
    "        return dist\n",
    "        \n",
    "def parse_operations(s1, s2):\n",
    "    if len(s1) == 0 and len(s2) == 0:\n",
    "        return\n",
    "    elif len(s1) == 0:\n",
    "        print('{}->{}: ADD {}'.format(s1, s2, s2))\n",
    "        return\n",
    "    elif len(s2) == 0:\n",
    "        print('{}->{}: DEL {}'.format(s1, s2, s1))\n",
    "        return\n",
    "        \n",
    "    op = operations[s1, s2]\n",
    "    print('{}->{}: {}'.format(s1, s2, op))\n",
    "    if 'Do Nothing' in op:\n",
    "        return parse_operations(s1[:-1], s2[:-1])\n",
    "    elif 'SUB' in op:\n",
    "        return parse_operations(s1[:-1], s2[:-1])\n",
    "    elif 'ADD' in op:\n",
    "        return parse_operations(s1, s2[:-1])\n",
    "    elif 'DEL' in op:\n",
    "        return parse_operations(s1[:-1], s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "ABCDECG->ABCCEF: SUB G->F\n",
      "ABCDEC->ABCCE: DEL C\n",
      "ABCDE->ABCCE: Do Nothing\n",
      "ABCD->ABCC: SUB D->C\n",
      "ABC->ABC: Do Nothing\n",
      "AB->AB: Do Nothing\n",
      "A->A: Do Nothing\n"
     ]
    }
   ],
   "source": [
    "s1 = 'ABCDECG'\n",
    "s2 = 'ABCCEF'\n",
    "print(edit_distance(s1, s2))\n",
    "parse_operations(s1, s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Complete the Pinyin auto-correction problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_dataset = '../week1/article_9k.txt'\n",
    "CHINESE_CHARACTERS = open(chinese_dataset).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MI'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHINESE_CHARACTERS[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def token(string):\n",
    "    return re.findall('[\\u4e00-\\u9fa5]+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外自本周', '月', '日']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token(CHINESE_CHARACTERS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ci wai zi ben zhou yue ri qi chu xiao mi shou ji deng kuan ji xing wai qi yu ji xing yi zan ting geng xin fa bu han kai fa ban ti yan ban nei ce wen ding ban zan bu shou ying xiang yi que bao gong cheng shi ke yi ji zhong quan bu jing li jin xing xi tong you hua gong zuo you ren cai ce zhe ye shi jiang jing li zhu yao yong dao de yan fa zhi zhong'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pinyin\n",
    "pinyin.get(''.join(token(CHINESE_CHARACTERS[:100])), format='strip', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHINESE_PINYIN = pinyin.get(''.join(token(CHINESE_CHARACTERS)), format='strip', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ci wai zi ben zhou yue ri qi chu xiao mi shou ji deng kuan ji xing wai qi yu ji xing yi zan ting gen'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHINESE_PINYIN[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pinyin(string):\n",
    "    return re.findall('[a-z]+', string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ci', 'wai', 'zi']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pinyin(CHINESE_PINYIN[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "counter = Counter(token_pinyin(CHINESE_PINYIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shi', 860634),\n",
       " ('de', 809887),\n",
       " ('yi', 682478),\n",
       " ('ji', 645276),\n",
       " ('guo', 430042),\n",
       " ('zhong', 409418),\n",
       " ('zhi', 398612),\n",
       " ('xin', 359619),\n",
       " ('li', 355441),\n",
       " ('zai', 334106)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit0(word):\n",
    "    return {word}\n",
    "\n",
    "# def splits(word):\n",
    "#     return [word[:i], word[i:] for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "def edit1(word):\n",
    "#     pairs = splits(word)\n",
    "    deletes = [word[:i] + word[i+1:] for i in range(len(word))]\n",
    "    inserts = [word[:i] + c + word[i:] for i in range(len(word)+1) for c in alphabet]\n",
    "    replaces = [word[:i] + c + word[i+1:] for i in range(len(word)) for c in alphabet]\n",
    "    transposes = [word[:i] + word[i+1] + word[i] + word[i+2:] for i in range(len(word)-1)]\n",
    "    return set(deletes + inserts + replaces + transposes)\n",
    "\n",
    "def edit2(word):\n",
    "    return {e2 for e1 in edit1(word) for e2 in edit1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    return {w for w in words if w in counter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bing',\n",
       " 'ding',\n",
       " 'jing',\n",
       " 'ling',\n",
       " 'ming',\n",
       " 'ning',\n",
       " 'pang',\n",
       " 'peng',\n",
       " 'pin',\n",
       " 'ping',\n",
       " 'qing',\n",
       " 'ting',\n",
       " 'xing',\n",
       " 'ying'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known(edit1('ping'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    candidates = (known(edit0(word)) or known(edit1(word)) or known(edit2(word)))\n",
    "    return max(candidates, key=counter.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ping'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('pign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ying'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('yign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yi'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('yngi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yi'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('ygi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sentences_pinyin(text_pinyin):\n",
    "    words = text_pinyin.split(' ')\n",
    "    return ' '.join([correct(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhe shi yi ge ce shi'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentences_pinyin('zhe sih yi ge ce sho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wo xiang shang qing hua da xue'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentences_pinyin('wo xiang shagn qinng hua da xeu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhe jiang gong ye da xue'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentences_pinyin('zhe jiang gogn ye da xue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思考题-homework？    \n",
    "#### 如何在不带空格的时候完成自动修整？--> 如何完成拼音的自动分割？   \n",
    "###### 提示：使用第一节课提到的语言模型!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = CHINESE_PINYIN.split(' ')\n",
    "word_list_2 = [''.join(word_list[i:i+2]) for i in range(len(word_list)-1)]\n",
    "counter_2 = Counter(word_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yueri', 165283),\n",
       " ('xinhua', 151830),\n",
       " ('huashe', 145990),\n",
       " ('zhongguo', 87894),\n",
       " ('waidai', 83330),\n",
       " ('nianyue', 78062),\n",
       " ('jizhe', 65398),\n",
       " ('erxian', 62431),\n",
       " ('daier', 61784),\n",
       " ('zhaopian', 52348)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prob2(word1, word2):\n",
    "#     if word1 + word2 in word_list_2:\n",
    "#         return counter_2[word1+word2] / sum(counter_2.values())\n",
    "#     else:\n",
    "#         return 0\n",
    "\n",
    "#在分隔拼音的时候，只考虑编辑距离为0和编辑距离为1的错误，使得分隔较为准确。\n",
    "def correct1(word):\n",
    "    candidates = (known(edit0(word)) or known(edit1(word)))\n",
    "    return max(candidates, key=counter.get)\n",
    "\n",
    "def get_prob1(word):\n",
    "    delta = 1e-5\n",
    "    #delta为惩罚因子，避免将类似'wode'的组合拼音识别为需要correct的一个单词'wo'而非'wo'+'de'。\n",
    "    if word in word_list:\n",
    "        return counter[word] / sum(counter.values())\n",
    "    else:\n",
    "        try:\n",
    "            correct_word = correct1(word)\n",
    "            return delta * counter[correct_word] / sum(counter.values())\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "splits = {}\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=2**10)\n",
    "def split_pinyin(words):\n",
    "    max_prob, split = max([(get_prob1(words),0)]\n",
    "                      + [((split_pinyin(words[:i]) * split_pinyin(words[i:])), i) for i in range(1, len(words))],\n",
    "                       key = lambda x:x[0])\n",
    "    splits[words] = split\n",
    "    return max_prob\n",
    "\n",
    "def parse(words):\n",
    "    max_prob = split_pinyin(words)\n",
    "    i = splits[words]\n",
    "    if i == 0:\n",
    "        return [words]\n",
    "    left, right = words[:i], words[i:]\n",
    "    return parse(left) + parse(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'qinnghuadaxeu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qing hua da xue'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_string = ' '.join(parse(string))\n",
    "correct_sentences_pinyin(split_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zhe shi yi ge ce shi'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_string = ' '.join(parse('zhesihyigecesho'))\n",
    "correct_sentences_pinyin(split_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pin yin shu ru fa'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_string = ' '.join(parse('pniyinshurufw'))\n",
    "correct_sentences_pinyin(split_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当前拼音纠错的模型只考虑单个拼音是否正确，还不能讲'shurifa'之类的错误更正为'shurufa'。后续如果在correct_sentence_pinyin中，加入n-gram语言模型，可能可以解决这种问题。另外，分隔拼音的split_pinyin函数，目前运行时间还是过长，还有改进的空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
